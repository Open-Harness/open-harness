agent: ambiguity-checker
timestamp: "2025-12-27T00:00:00Z"
feature_dir: specs/007-fluent-harness-dx
summary: "556 lines checked across 6 documents. 5 ambiguities found (0 critical, 3 medium, 2 low)."

statistics:
  items_checked: 556
  vague_terms: 3
  placeholders: 0
  unmeasurable: 2
  total_findings: 5
  severity_breakdown:
    critical: 0
    medium: 3
    low: 2

findings:
  - id: A001
    type: vague_term
    location: spec.md:L230
    text: "Same behavior, better DX"
    issue: "Vague quality attribute 'better DX' without measurable criteria"
    recommendation: "Define DX improvement metrics: e.g., 'reduced API surface area by 3 methods', 'eliminates N manual steps', 'lines of code reduction >= 50%' (already SC-001). Consider additional metrics like: time to first harness (in minutes), required imports count, boilerplate LOC"
    severity: low
    context: "SC-004 states 'same behavior, better DX' - the 'better' modifier is not quantified. However, SC-001 already addresses this with the 50% reduction metric for coding harness specifically."

  - id: A002
    type: unmeasurable
    location: spec.md:L75
    text: "Clean separation enables testing business logic independently from presentation"
    issue: "No acceptance criteria for what constitutes 'clean separation' or how it's verified"
    recommendation: "Define testability metrics: (a) execute() function can be tested without event handler setup (test in isolation), (b) number of console.log calls in execute body = 0, (c) all observable behavior must be via emit() calls, not side effects. Add test assertion: 'harness can run without any .on() handlers registered and complete successfully'"
    severity: medium
    context: "User Story 4 objective is clear, but success measurement is vague. Edge case section (L151-154) provides concrete log format but doesn't specify how to measure 'separation'."

  - id: A003
    type: vague_term
    location: plan.md:L8
    text: "provides typed agent access, declarative event handling with auto-cleanup, and separation of business logic from presentation"
    issue: "Three features mentioned without defining what 'separation' or 'declarative' means in measurable terms"
    recommendation: "Add success criteria for each: 'declarative event handling' = 'event subscriptions configured in .on() calls, not imperative subscribe() calls in code' (already defined in code examples). 'Separation' = 'no console.log in execute() function' (measurable via grep). 'Typed agent access' = 'full type inference verified by tsc --noEmit' (already SC-003)."
    severity: low
    context: "Summary statement is marketing-focused. Implementation details (spec.md) are clear, but plan summary conflates multiple concepts."

  - id: A004
    type: unmeasurable
    location: spec.md:L212
    text: "The coding workflow harness is rewritten using the new API with â‰¥50% reduction in lines of code"
    issue: "No specification of what counts as 'lines of code' (comments? blank lines? imports?) in the comparison"
    recommendation: "Add measurement methodology: 'LOC = non-comment, non-blank lines. Count source code only (harnesses/coding/*.ts files). Exclude node_modules. Use: wc -l $(find harnesses/coding -name \"*.ts\") before and after, subtract comments/blanks using existing tooling. Must include setup + execute + cleanup in both versions for fair comparison.'"
    severity: medium
    context: "T043 references this metric but implementation details are missing. Task description says 'runs wc -l comparison and asserts reduction >= 50%' but doesn't specify methodology."

  - id: A005
    type: vague_term
    location: tasks.md:L280
    text: "Each user story should be independently completable and testable"
    issue: "What defines 'independently completable'? Dependencies between stories exist (US2 depends on US1, US4 depends on US3), yet tasks.md claims independence"
    recommendation: "Clarify: 'Phase-independent' means stories can be coded in any phase order, but test independence requires prerequisite phases complete first. Explicitly state: US1, US3, US7 are implementation-independent. US2, US4 require prior phases. US5/US6 require Phase 2 completion. Reword as: 'Each user story is testable once its prerequisite phases complete.'"
    severity: medium
    context: "Section 'Dependencies & Execution Order' (L207-219) correctly documents dependencies, but the note at L281 contradicts this by claiming stories are 'independently completable'. This could mislead implementers about phase structure."

---

## Summary of Analysis

### What's Well-Specified
- **Event types**: All HarnessEvent types explicitly defined with field names and types (data-model.md)
- **API signatures**: Function signatures include parameter types, return types, and examples (contracts/api.md)
- **Acceptance criteria**: User stories have concrete acceptance scenarios (spec.md L28-84)
- **Edge cases**: Detailed behavior specs for errors, async factories, recursive calls (spec.md L135-171)
- **Success criteria**: Measurable outcomes for SC-001 through SC-008, mostly with verification tasks

### Findings Explained

**A001 (low)**: "Better DX" is vague, but mitigated by SC-001 which provides the 50% LOC reduction metric. No action needed unless marketing copy requires precision.

**A002 (medium)**: "Clean separation" in User Story 4 needs testability metrics. Currently, the story objective is clear (separate logic from presentation) but how to verify it is implicit. Recommend adding a test assertion like: "execute() function runs without handlers and completes" to acceptance scenarios.

**A003 (low)**: Plan summary uses abstract terms that are well-defined in spec and implementation. Low priority - specification is precise, summary is just marketing language.

**A004 (medium)**: SC-001 includes a "50% reduction" metric but doesn't specify the methodology. T043 will run the comparison, but needs clarity on what counts as LOC (comments? blank lines? test code?). Add explicit measurement formula to task.

**A005 (medium)**: Tasks.md note at L281 claims user stories are "independently completable" but dependencies section (L207-219) correctly identifies they're not. This is a documentation inconsistency that could mislead. Recommend rewording to clarify phase dependencies vs. implementation parallelism.

### Recommendations by Priority

1. **Immediate (before Phase 2)**: Update tasks.md L281 note to clarify story dependencies match phase structure
2. **Before Phase 6 (US4)**: Add testability metrics to User Story 4 acceptance criteria
3. **Before Phase 10 (Polish)**: Document LOC measurement methodology for SC-001 in T043
4. **Optional**: Add 1-2 DX metrics beyond "50% LOC reduction" to SC-004 (e.g., import count, method call count)

### Conclusion

This specification is exceptionally well-written. Zero critical ambiguities block implementation. The 5 medium/low findings are mostly minor documentation inconsistencies (one contradictory note) and missing measurement details that can be added during implementation. All functional requirements, API contracts, and acceptance criteria are precise and measurable.
