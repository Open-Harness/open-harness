---
title: How to Add Voice Integration
description: Integrate voice I/O with flows
---

# How to Add Voice Integration

Add real-time voice interaction to your flows using voice channels.

## Available Voice Channels

| Channel | Provider | Status |
|---------|----------|--------|
| rtv-channel | OpenAI Realtime | Experimental |
| [ElevenLabs](/docs/reference/channels/elevenlabs) | ElevenLabs Conversational AI | Planned |

## rtv-channel (OpenAI Realtime)

### Install

```bash
bun add @open-harness/rtv-channel
```

### Basic Setup

```typescript
import { createFlowRunner } from "@open-harness/kernel";
import { createRTVChannel } from "@open-harness/rtv-channel";

const voiceChannel = createRTVChannel({
  model: "gpt-4o-realtime-preview",
  voice: "alloy",
  inputAudioFormat: "pcm16",
  outputAudioFormat: "pcm16"
});

const runner = createFlowRunner(flow, registry);
runner.attach(voiceChannel);
await runner.run();
```

### Voice Options

```typescript
createRTVChannel({
  // Model
  model: "gpt-4o-realtime-preview",

  // Voice: alloy, echo, shimmer, ash, ballad, coral, sage, verse
  voice: "alloy",

  // Audio formats
  inputAudioFormat: "pcm16",
  outputAudioFormat: "pcm16",

  // Behavior
  turnDetection: "server_vad",
  silenceThresholdMs: 500,

  // Session limits
  maxDuration: 300, // 5 minutes
});
```

### Listen to Voice Events

```typescript
hub.subscribe("voice:input", (event) => {
  console.log("User said:", event.event.transcript);
});

hub.subscribe("voice:output", (event) => {
  console.log("Speaking:", event.event.text);
});

hub.subscribe("voice:error", (event) => {
  console.error("Voice error:", event.event.error);
});
```

## ElevenLabs Channel (Coming Soon)

The ElevenLabs channel will provide:

- Voice narration of flow progress
- Voice commands (pause, resume, status, abort)
- Human-in-the-loop voice prompts
- Lower latency via WebSocket

```typescript
// Planned API
import { ElevenLabsChannel } from "@open-harness/elevenlabs";

runner.attach(ElevenLabsChannel({
  agentId: process.env.ELEVENLABS_AGENT_ID,
  verbosity: "normal",
}));

runner.startSession(); // Enable voice commands
```

See [ElevenLabs Channel Reference](/docs/reference/channels/elevenlabs) for the planned design.

## Combining Voice + Console

```typescript
import { ConsoleChannel } from "@open-harness/kernel";

const runner = createFlowRunner(flow, registry);

runner.attach(voiceChannel);    // Voice I/O
runner.attach(ConsoleChannel()); // Visual fallback

await runner.run();
```

Both channels receive events independently - voice narrates while console shows details.

## Related

- [ElevenLabs Reference](/docs/reference/channels/elevenlabs) - Planned voice channel
- [Bidirectional I/O](/docs/guides/channels/bidirectional-io) - Two-way patterns
- [Console Channel](/docs/guides/channels/console-channel) - Text fallback
