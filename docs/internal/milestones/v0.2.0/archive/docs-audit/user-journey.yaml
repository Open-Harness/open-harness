# User Journey & Friction Analysis for Open Harness Documentation
# Generated: 2026-01-08
# Analysis: A frustrated developer's perspective on navigating these docs

journey_map:
  landing:
    current_experience: |
      User lands on index.mdx and sees: "Open Harness is an event-driven workflow
      execution system for building production multi-agent AI systems."

      The four bullet points (Declarative Workflows, Full Observability, JSONata
      Expressions, Replay Testing) are features, not benefits. The example YAML
      shows a research-and-summarize flow but doesn't explain what actually runs.

      Four cards point to: Quickstart, Architecture, JSONata Bindings, API Reference.
      Architecture is an odd second choice - sends users into deep concepts before
      they've built anything.

    ideal_experience: |
      User immediately understands: "This orchestrates AI agents in production."
      They see what they can BUILD (not features): customer support bot, code review
      pipeline, research assistant. They have ONE clear path: "Start Here" button.

    friction_score: 4

    friction_points:
      - point: "No clear value proposition"
        severity: high
        quote: "Event-driven workflow execution system for building production multi-agent AI systems"
        fix: "Open Harness orchestrates AI agents to build multi-step workflows - like having Claude research, then summarize, then act. Define it in YAML, observe everything, test deterministically."

      - point: "Features listed, not benefits"
        severity: high
        quote: "Declarative Workflows: Define agent pipelines in YAML, not imperative code"
        fix: "Instead of 'Declarative Workflows', say: 'Write a 20-line YAML file instead of 500 lines of orchestration code'"

      - point: "Example shows YAML but not what it produces"
        severity: medium
        quote: "The quick example shows flow definition but no output"
        fix: "Add 'Run this and you get:' followed by actual output showing the research result and summary"

      - point: "Architecture as second card is wrong"
        severity: medium
        quote: "<Card title='Architecture' href='/docs/concepts/architecture'>"
        fix: "Replace with 'Build Your First Agent' or 'What Can I Build?'"

    dead_ends:
      - question: "What can I actually build with this?"
        answer_exists: false
        where_user_looks: "index.mdx"

      - question: "Is this better than LangChain/CrewAI?"
        answer_exists: false
        where_user_looks: "index.mdx, concepts"

      - question: "Does this work with GPT-4/Gemini?"
        answer_exists: false
        where_user_looks: "index.mdx"

    gaps:
      - "No 30-second elevator pitch"
      - "No comparison to alternatives"
      - "No use case gallery"
      - "No 'what makes this different' section"

  getting_started:
    current_experience: |
      User clicks Quickstart and sees they need:
      - Bun 1.0+
      - A terminal

      They run 4 commands to create a project, then create flow.yaml and run.ts.
      The example uses a CUSTOM node (hello.agent) that the user has to define
      themselves - NOT the built-in claude.agent shown in the landing example.

      The code works but doesn't actually use Claude. The "What Just Happened?"
      section claims they "passed that node directly to runFlow()" but they
      actually created a registry inline.

      Next steps point to "Your First Agent" which is about branching, not
      actually building an LLM-powered agent.

    ideal_experience: |
      User copies 10 lines total, runs it, sees Claude respond. No custom nodes.
      Clear explanation of what happened. Next step is "Make it do more" not
      "understand branching."

    friction_score: 4

    friction_points:
      - point: "First example doesn't use Claude at all"
        severity: critical
        quote: "const helloAgent = { type: 'hello.agent' as const, run: async (_ctx: any, input: { name: string }) => ({ message: `Hello, ${input.name}!` }) }"
        fix: "Use claude.agent from the SDK. The first thing users want is to see AI work."

      - point: "Landing example and Quickstart example don't match"
        severity: high
        quote: "Landing shows claude.agent, quickstart shows custom hello.agent"
        fix: "Either landing should show the quickstart pattern or quickstart should use claude.agent"

      - point: "'Your First Agent' is misnamed"
        severity: high
        quote: "title: Your First Agent - Build a multi-node flow with conditions and state"
        fix: "This is about branching/state, not building an agent. Rename to 'Adding Branching Logic'"

      - point: "Missing auth/API key setup"
        severity: medium
        quote: "Prerequisites: Bun 1.0+, A terminal"
        fix: "If users want to use Claude, they need ANTHROPIC_API_KEY. But actually, the CLAUDE.md says NOT to set this and use Claude Code auth. This is confusing."

      - point: "No npm/pnpm alternative"
        severity: low
        quote: "bun init -y, bun add @open-harness/sdk"
        fix: "Show npm/yarn alternatives since most users aren't on Bun"

    dead_ends:
      - question: "How do I use this with Claude?"
        answer_exists: true
        where_user_looks: "quickstart.mdx (wrong place)"
        actual_location: "guides/agents/claude-agent.mdx (3 clicks away)"

      - question: "What's the minimum code to get Claude to respond?"
        answer_exists: false
        where_user_looks: "quickstart.mdx"

      - question: "How do I set up authentication?"
        answer_exists: partially
        where_user_looks: "quickstart.mdx, production.mdx"
        actual_location: "production.mdx mentions ANTHROPIC_API_KEY as optional but doesn't explain Claude Code auth"

    gaps:
      - "No copy-paste example that actually calls an LLM"
      - "No explanation of authentication"
      - "No troubleshooting section for common first-run errors"
      - "No working example repo link"

  first_problem:
    current_experience: |
      When code fails, the user gets:
      - No error page or troubleshooting guide anywhere in docs
      - node:error event exists but no guidance on interpreting it
      - Common errors (missing node type, bad expression, auth failure) have
        no documented solutions

      The 'events' reference shows error events exist but not what to do about them.
      The production.mdx shows error handling pattern but it's in deployment docs,
      not a troubleshooting guide.

    ideal_experience: |
      Dedicated troubleshooting page with:
      - Common errors and solutions
      - How to read error events
      - Debug mode / verbose logging
      - FAQ section

    friction_score: 5

    friction_points:
      - point: "Zero troubleshooting documentation"
        severity: critical
        quote: "(no quote - it doesn't exist)"
        fix: "Create docs/learn/troubleshooting.mdx with common errors"

      - point: "Error events documented but not actionable"
        severity: high
        quote: "{ type: 'node:error', nodeId: 'echo', runId: 'run-123', error: 'timeout' }"
        fix: "Explain what errors mean and how to fix them"

      - point: "Debug mode not documented"
        severity: high
        quote: "(no quote - not mentioned)"
        fix: "Document how to enable verbose logging, inspect snapshots"

    dead_ends:
      - question: "Why is my expression not evaluating?"
        answer_exists: partially
        where_user_looks: "troubleshooting (doesn't exist)"
        actual_location: "bindings.mdx has a small 'Troubleshooting' section"

      - question: "How do I see what's happening?"
        answer_exists: false
        where_user_looks: "debugging section (doesn't exist)"

      - question: "My flow just hangs - what's wrong?"
        answer_exists: false
        where_user_looks: "anywhere"

    gaps:
      - "No troubleshooting guide"
      - "No FAQ"
      - "No 'Common Errors' page"
      - "No Discord/GitHub link for support"

  understanding:
    current_experience: |
      User goes to Concepts and finds 6 pages:
      - Architecture (Hub, Runtime, Channels)
      - Event System
      - Expressions (JSONata overview)
      - Why JSONata (philosophy)
      - Persistence
      - Design Decisions (nested: graph-first)

      Architecture uses Mermaid diagrams that are helpful but introduces 5 new
      concepts at once (Hub, Runtime, Agents, Channels, Transports). The
      distinction between Channel and Transport is confusing for beginners.

      Terms are not consistently used across pages. Hub.mdx in reference is
      actually titled "Runtime" and covers createRuntime, not Hub.

    ideal_experience: |
      Concepts are introduced progressively:
      1. Flow = nodes + edges
      2. Runtime executes flows
      3. Events let you observe
      4. Expressions connect data

      Each concept links to the next. Terms are defined when first used.

    friction_score: 3

    friction_points:
      - point: "Too many concepts at once in Architecture"
        severity: medium
        quote: "Hub, Runtime, Agents, Channels, Transports - all introduced in one page"
        fix: "Split into 'Core Concepts' (Flow, Node, Edge) and 'Advanced Concepts' (Hub, Channel, Transport)"

      - point: "Channel vs Transport distinction is confusing"
        severity: medium
        quote: "Channel: the protocol contract... Transport: the implementation detail"
        fix: "Most users don't need this distinction. Hide in advanced section."

      - point: "Reference/api/hub.mdx is misnamed"
        severity: high
        quote: "File is hub.mdx but title is 'Runtime'"
        fix: "Either rename file to runtime.mdx or update title to match"

      - point: "Why JSONata page is defensive, not explanatory"
        severity: low
        quote: "Why Not Template Strings or JavaScript"
        fix: "Users don't care why you didn't use alternatives. Show what JSONata enables."

    dead_ends:
      - question: "What's the mental model for how this works?"
        answer_exists: partially
        where_user_looks: "architecture.mdx"
        actual_location: "Scattered across multiple pages"

      - question: "How do nodes communicate?"
        answer_exists: true
        where_user_looks: "architecture.mdx (not found)"
        actual_location: "expressions/bindings.mdx"

    gaps:
      - "No glossary"
      - "No progressive concept introduction"
      - "No 'mental model' diagram showing data flow simply"

  reference_lookup:
    current_experience: |
      Reference section has 4 subsections:
      - API (7 pages)
      - Expressions (3 pages)
      - Types (4 pages)
      - Schemas (1 page)

      API pages are inconsistently structured. Some show types first, some
      show usage first. The hub.mdx page shows THREE different APIs (runFlow,
      createHarness, createRuntime) which is confusing.

      Types pages show TypeScript interfaces which is good, but properties
      aren't always documented. FlowDefinition shows `input?: ZodSchema` but
      doesn't show how to use it in YAML.

      No search functionality apparent (depends on docs framework).

    ideal_experience: |
      - Consistent API page format: Overview, Quick Usage, Methods, Types
      - Every type property has a description
      - Examples show both TypeScript AND YAML where applicable
      - Searchable/indexed

    friction_score: 3

    friction_points:
      - point: "Hub page shows 3 different APIs without clear guidance"
        severity: high
        quote: "runFlow, createHarness, createRuntime - all on one page"
        fix: "Split into 'Quick Start API' (runFlow), 'Standard API' (createHarness), 'Advanced API' (createRuntime) OR add decision tree"

      - point: "Type properties lack descriptions"
        severity: medium
        quote: "inputSchema?: unknown; outputSchema?: unknown; capabilities?: { streaming?: boolean; multiTurn?: boolean };"
        fix: "Add description for every property"

      - point: "YAML schema and TypeScript types are separate"
        severity: medium
        quote: "flow-yaml.mdx and flow-definition.mdx cover same thing differently"
        fix: "Combine or clearly cross-reference"

      - point: "control-flow.mdx uses wrong syntax"
        severity: high
        quote: "uses {{ nodes.step1.output.text }} but learn pages use {{ step1.text }}"
        fix: "Standardize syntax across all docs. The correct syntax is {{ nodeId.field }}, not {{ nodes.nodeId.output.field }}"

    dead_ends:
      - question: "What are all the built-in node types?"
        answer_exists: partially
        where_user_looks: "node-registry.mdx"
        actual_location: "Table shows 3 nodes but not complete list"

      - question: "What events can I subscribe to?"
        answer_exists: true
        where_user_looks: "events.mdx (found it)"

      - question: "How do I validate flow input?"
        answer_exists: partially
        where_user_looks: "flow-definition.mdx shows Zod but not YAML"

    gaps:
      - "No complete list of built-in node types"
      - "No complete list of built-in events"
      - "Inconsistent syntax across pages"

critical_gaps:
  - gap: "No real Claude example in quickstart"
    user_question: "How do I get Claude to do something?"
    severity: critical
    affected_stages: [landing, getting_started]

  - gap: "Zero troubleshooting documentation"
    user_question: "Something broke, how do I fix it?"
    severity: critical
    affected_stages: [first_problem]

  - gap: "Authentication is unclear"
    user_question: "Do I need an API key? How do I set it up?"
    severity: high
    affected_stages: [getting_started, first_problem]

  - gap: "Inconsistent expression syntax in examples"
    user_question: "Is it {{ nodeId.field }} or {{ nodes.nodeId.output.field }}?"
    severity: high
    affected_stages: [understanding, reference_lookup]

  - gap: "No comparison to alternatives"
    user_question: "Why should I use this instead of LangChain/CrewAI?"
    severity: medium
    affected_stages: [landing]

  - gap: "Missing practical use cases"
    user_question: "What can I actually build?"
    severity: medium
    affected_stages: [landing, getting_started]

user_flow_breaks:
  - from: "index.mdx"
    expected_next: "quickstart.mdx"
    actual_next: "Correct - Quickstart is first card"
    fix: null

  - from: "quickstart.mdx"
    expected_next: "Example using Claude"
    actual_next: "your-first-agent.mdx (branching, not Claude)"
    fix: "Add 'Using Claude' tutorial between quickstart and your-first-agent"

  - from: "your-first-agent.mdx"
    expected_next: "multi-agent-flow.mdx"
    actual_next: "Links to architecture (too early)"
    fix: "Should link to multi-agent-flow first, architecture later"

  - from: "multi-agent-flow.mdx"
    expected_next: "Runs the example"
    actual_next: "Example uses createRuntime (not defined in learn section)"
    fix: "Example should use createHarness which was introduced in your-first-agent"

  - from: "claude-agent.mdx"
    expected_next: "Works immediately"
    actual_next: "No auth instructions - will fail for users without Claude Code"
    fix: "Add auth setup or link to auth docs"

top_5_friction_points:
  1:
    description: "Quickstart doesn't actually use Claude"
    impact: "Users came to orchestrate AI agents. First example has no AI. They bounce."
    fix: "Replace hello.agent with claude.agent example that actually calls Claude"

  2:
    description: "No troubleshooting documentation exists"
    impact: "First error sends users to Google/Discord with no docs to reference. They abandon."
    fix: "Create troubleshooting.mdx with common errors and solutions"

  3:
    description: "Authentication is completely undocumented"
    impact: "Users don't know if they need API key, how to set it, or if Claude Code auth works."
    fix: "Add clear auth section in quickstart or dedicated auth page"

  4:
    description: "Expression syntax inconsistent across pages"
    impact: "Users copy examples, they fail, they blame themselves or the product."
    fix: "Audit all pages and standardize on {{ nodeId.field }} syntax"

  5:
    description: "Concept overload in Architecture"
    impact: "Users trying to understand the system get 5 new terms in one page."
    fix: "Progressive disclosure: basics first, advanced concepts later"

navigation_issues:
  - issue: "meta.json puts concepts LAST but many learn pages link there"
    location: "apps/docs/content/docs/meta.json"
    severity: medium
    fix: "Consider making concepts accessible earlier or not linking to them from learn"

  - issue: "Reference index page exists but is hidden"
    location: "reference/index.mdx exists but meta.json uses folder structure"
    severity: low
    fix: "Ensure index page is discoverable"

syntax_inconsistencies:
  - issue: "Flow output access varies by page"
    examples:
      - "{{ researcher.text }} (multi-agent-flow.mdx) - CORRECT"
      - "{{ nodes.step1.output.text }} (control-flow.mdx) - WRONG"
      - "{{ triage.summary }} (your-first-agent.mdx) - CORRECT"
    correct_syntax: "{{ nodeId.field }}"

  - issue: "Condition syntax varies"
    examples:
      - "when: \"triage.priority = 'urgent'\" (conditionals.mdx) - CORRECT"
      - "condition: \"{{ nodes.classify.output.type = 'bug' }}\" (flow-definition.mdx) - WRONG"
    correct_syntax: "Use 'when' property with JSONata expression, no double-braces in when"

recommendations:
  immediate:
    - action: "Create quickstart with actual Claude usage"
      priority: P0
      effort: 2h

    - action: "Create troubleshooting.mdx"
      priority: P0
      effort: 4h

    - action: "Fix syntax inconsistencies"
      priority: P0
      effort: 2h

  short_term:
    - action: "Add auth documentation"
      priority: P1
      effort: 2h

    - action: "Rename 'Your First Agent' to something accurate"
      priority: P1
      effort: 30min

    - action: "Add Claude-focused tutorial after quickstart"
      priority: P1
      effort: 4h

  medium_term:
    - action: "Restructure concepts for progressive disclosure"
      priority: P2
      effort: 8h

    - action: "Add use case gallery"
      priority: P2
      effort: 8h

    - action: "Create glossary"
      priority: P2
      effort: 4h
